{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:53:43.607074Z",
     "start_time": "2021-06-20T18:53:42.352541Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import translators as ts\n",
    "import re\n",
    "from datetime import datetime\n",
    "from langdetect import detect\n",
    "from json_parsers import *\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:53:43.926443Z",
     "start_time": "2021-06-20T18:53:43.898790Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "# Connection parameters, yours will be different\n",
    "params = {\n",
    "    \"host\"      : \"localhost\",\n",
    "    \"database\"  : \"frenchgp\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"\"\n",
    "}\n",
    "def connect(params_dic):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn\n",
    "\n",
    "def getDrivers(df):\n",
    "    driver_arr = np.unique([drivers_id[i] for i in drivers if re.search(i, df['translated_text'].lower())])\n",
    "    return driver_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:54:12.015398Z",
     "start_time": "2021-06-20T18:54:12.010797Z"
    }
   },
   "outputs": [],
   "source": [
    "client_db =  'stream'\n",
    "client_col = 'frenchgp_authors' #args.collection\n",
    "\n",
    "# source and target connections\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "# database and collection names\n",
    "db = client[client_db]\n",
    "col = db[client_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:54:02.727905Z",
     "start_time": "2021-06-20T18:54:01.570950Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(col.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:01:45.527670Z",
     "start_time": "2021-06-20T21:01:45.516232Z"
    }
   },
   "outputs": [],
   "source": [
    "def getData(df):\n",
    "    \"\"\"\n",
    "    Convert the nexted json inside the data column to its own dataframe\n",
    "    \"\"\"\n",
    "    df['author_id'] = df.apply(lambda df: parse_json(df, 'data', 'author_id'), 1)\n",
    "    df['created_at'] = df.apply(lambda df: parse_json(df, 'data', 'created_at'), 1)\n",
    "    df['geo'] = df.apply(lambda df: parse_json(df, 'data', 'geo'), 1)\n",
    "    df['tweet_id'] = df.apply(lambda df: parse_json_exact(df, 'data', 'id'), 1)\n",
    "    df['raw_text'] = df.apply(lambda df: parse_json(df, 'data', 'text'), 1)\n",
    "    df = df[['tweet_id', 'author_id', 'created_at', 'raw_text']]\n",
    "    return df\n",
    "\n",
    "\n",
    "def getTranslation(df):\n",
    "    clean_text = df['clean_text']\n",
    "    try:\n",
    "        translated_text = ts.google(clean_text, if_use_cn_host=True)\n",
    "    except Exception:\n",
    "        translated_text = clean_text\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "def getCleanText(df):\n",
    "    clean_text = ''.join(e for e in df['raw_text'] if e.isascii())\n",
    "    clean_text = ''.join(e for e in clean_text if e not in [\"!\", \"@\", \"#\"])\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def getRawText(df, column):\n",
    "    raw_text = ''.join(e for e in df[column] if e.isascii())\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def getLanguage(df):\n",
    "    clean_text = ''.join(e for e in df['raw_text'] if e.isascii())\n",
    "    clean_text = ''.join(e for e in clean_text if e not in [\"!\", \"@\", \"#\"])\n",
    "    try:\n",
    "        language = detect(clean_text)\n",
    "    except Exception:\n",
    "        language = ''\n",
    "    return language\n",
    "\n",
    "\n",
    "def getUsers(df):\n",
    "    users = df['includes']['users']\n",
    "    return users\n",
    "\n",
    "\n",
    "def getUserDataframe(df):\n",
    "    df['user_created_at'] = df.apply(\n",
    "        lambda df: parse_json(df, 'users', 'created_at'), 1)\n",
    "    df['user_id'] = df.apply(lambda df: parse_json(df, 'users', 'id'), 1)\n",
    "    df['location'] = df.apply(\n",
    "        lambda df: parse_json(df, 'users', 'location'), 1)\n",
    "    df['name'] = df.apply(lambda df: parse_json_exact(df, 'users', 'name'), 1)\n",
    "    df['username'] = df.apply(\n",
    "        lambda df: parse_json(df, 'users', 'username'), 1)\n",
    "    df = df.drop(['users'], 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def escapeArray(df, column):\n",
    "    if len(df[column]) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:54:59.454942Z",
     "start_time": "2021-06-20T18:54:50.964179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iiyakhruschev/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ CLEAN TWEET DATA / TRANSLATE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "data_df = getData(df)\n",
    "\n",
    "for column in list(data_df):\n",
    "    data_df[column] = data_df.apply(\n",
    "        lambda data_df: escapeArray(data_df, column), 1)\n",
    "\n",
    "for i, j in zip(data_df['tweet_id'], range(len(data_df))):\n",
    "    if isinstance(i, np.ndarray):\n",
    "        data_df['tweet_id'][j] = data_df['tweet_id'][j][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T17:59:02.474938Z",
     "start_time": "2021-06-20T17:59:02.465899Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T02:59:00.806290Z",
     "start_time": "2021-06-20T02:59:00.576555Z"
    }
   },
   "outputs": [],
   "source": [
    "driver = pd.read_csv(\"../../../data/driver.csv\")\n",
    "engine = create_engine('postgresql://postgres@localhost:5432/frenchgp')\n",
    "driver.to_sql('driver', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T22:26:09.076954Z",
     "start_time": "2021-06-20T22:26:08.834769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT tweet_id, author_id, created_at, language, translated_text FROM tweet;\n",
    "    \"\"\", con = connect(params))\n",
    "\n",
    "tweets = tweets[tweets['tweet_id'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T22:26:35.743462Z",
     "start_time": "2021-06-20T22:26:35.735906Z"
    }
   },
   "outputs": [],
   "source": [
    "drivers = [\n",
    "    'max', 'verstappen', 'lewis', 'hamilton', 'sergio', 'perez', 'lando',\n",
    "    'norris', 'charles', 'leclerc', 'valtteri', 'bottas', 'carlos', 'sainz',\n",
    "    'pierre', 'gasly', 'sebastian', 'vettel', 'daniel', 'ricciardo',\n",
    "    'fernando', 'alonso', 'esteban', 'ocon', 'lance', 'stroll', 'yuki',\n",
    "    'tsunoda', 'kimi', 'raikkonen', 'antonio', 'giovinazzi', 'mick',\n",
    "    'schumacher', 'george', 'russell', 'nikita', 'mazepin', 'nicholas',\n",
    "    'latifi'\n",
    "]\n",
    "drivers_id = {\n",
    "    'max': 1,\n",
    "    'verstappen': 1,\n",
    "    'lewis': 2,\n",
    "    'hamilton': 2,\n",
    "    'sergio': 3,\n",
    "    'perez': 3,\n",
    "    'lando': 4,\n",
    "    'norris': 4,\n",
    "    'charles': 5,\n",
    "    'leclerc': 5,\n",
    "    'valtteri': 6,\n",
    "    'bottas': 6,\n",
    "    'carlos': 7,\n",
    "    'sainz': 7,\n",
    "    'pierre': 8,\n",
    "    'gasly': 8,\n",
    "    'sebastian': 9,\n",
    "    'vettel': 9,\n",
    "    'daniel': 10,\n",
    "    'ricciardo': 10,\n",
    "    'fernando': 11,\n",
    "    'alonso': 11,\n",
    "    'esteban': 12,\n",
    "    'ocon': 12,\n",
    "    'lance': 13,\n",
    "    'stroll': 13,\n",
    "    'yuki': 14,\n",
    "    'tsunoda': 14,\n",
    "    'kimi': 15,\n",
    "    'raikkonen': 15,\n",
    "    'antonio': 16,\n",
    "    'giovinazzi': 16,\n",
    "    'mick': 17,\n",
    "    'schumacher': 17,\n",
    "    'george': 18,\n",
    "    'russell': 18,\n",
    "    'nikita': 19,\n",
    "    'mazepin': 19,\n",
    "    'nicholas': 20,\n",
    "    'latifi': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DRIVER ENTITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T22:26:51.825561Z",
     "start_time": "2021-06-20T22:26:39.672268Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets['driver_id'] = tweets.apply(lambda tweets: getDrivers(tweets), 1)\n",
    "driver_assign = tweets[['tweet_id', 'driver_id']]\n",
    "driver_assign = driver_assign.explode('driver_id')\n",
    "driver_assign = driver_assign.dropna(axis=0)\n",
    "driver_assign['driver_id'] = driver_assign['driver_id'].astype(int)\n",
    "driver_assign.to_sql('driver_entities', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T03:12:21.294414Z",
     "start_time": "2021-06-20T03:12:21.285265Z"
    }
   },
   "outputs": [],
   "source": [
    "driver_assign.sort_values('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T03:10:43.251159Z",
     "start_time": "2021-06-20T03:10:43.243763Z"
    }
   },
   "outputs": [],
   "source": [
    "driver_assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET TWEET META DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:00:42.271497Z",
     "start_time": "2021-06-20T18:00:40.835800Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def auth():\n",
    "    return os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "def create_url(tweet_id):\n",
    "#     tweet_fields = \"tweet.fields=lang,author_id\"\n",
    "    tweet_fields = 'tweet.fields=public_metrics,geo'\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    id = \"ids={}\".format(tweet_id)\n",
    "    # You can adjust ids to include a single Tweets.\n",
    "    # Or you can add to up to 100 comma-separated IDs\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(id, tweet_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def main():\n",
    "    bearer_token = auth()\n",
    "    url = create_url(tweets['tweet_id'][0])\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    print(json_response, \"\\n\\n\")\n",
    "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:41:47.309092Z",
     "start_time": "2021-06-20T18:41:47.305514Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "batch = 0\n",
    "batch_size = 100\n",
    "batches = math.ceil(len(data_df)/batch_size)\n",
    "ids = str(list(data_df['tweet_id'][batch*batch_size:batch*batch_size+batch_size]))\\\n",
    "    .replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:20:07.183219Z",
     "start_time": "2021-06-20T18:20:07.180507Z"
    }
   },
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:42:23.812370Z",
     "start_time": "2021-06-20T18:42:10.386074Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for batch in range(batches):   \n",
    "    try:\n",
    "        ids = str(list(data_df['tweet_id'][batch*batch_size:batch*batch_size+batch_size-1]))\\\n",
    "            .replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")\n",
    "        bearer_token = auth()\n",
    "        url = create_url(ids)\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(url, headers)\n",
    "        col.insert_many(json_response['data'])\n",
    "        print(batch)\n",
    "    except:\n",
    "        print(batch)\n",
    "#     print(batch*batch_size, batch*batch_size+batch_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:37:39.590521Z",
     "start_time": "2021-06-20T18:37:39.587940Z"
    }
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:38:35.891915Z",
     "start_time": "2021-06-20T18:38:35.333575Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for batch in range(442, batches)\n",
    "ids = str(list(data_df['tweet_id'][442*batch_size:]))\\\n",
    "    .replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")\n",
    "bearer_token = auth()\n",
    "url = create_url(ids)\n",
    "headers = create_headers(bearer_token)\n",
    "json_response = connect_to_endpoint(url, headers)\n",
    "# col.insert_many(json_response['data'])\n",
    "print(batch)\n",
    "#     print(batch*batch_size, batch*batch_size+batch_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:39:48.473414Z",
     "start_time": "2021-06-20T18:39:48.470818Z"
    }
   },
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:19:33.585628Z",
     "start_time": "2021-06-20T18:19:33.563956Z"
    }
   },
   "outputs": [],
   "source": [
    "json_response['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL META"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:43:07.711718Z",
     "start_time": "2021-06-20T18:43:07.251678Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(list(col.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:43:41.139520Z",
     "start_time": "2021-06-20T18:43:41.108284Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('id', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:43:44.456986Z",
     "start_time": "2021-06-20T18:43:44.443658Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:44:24.584215Z",
     "start_time": "2021-06-20T18:44:20.013994Z"
    }
   },
   "outputs": [],
   "source": [
    "df['retweet_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'retweet_count'), 1)\n",
    "df['reply_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'reply_count'), 1)\n",
    "df['like_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'like_count'), 1)\n",
    "df['quote_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'quote_count'), 1)\n",
    "# df['tweet_id'] = df.apply(lambda df: parse_json(df, 'data', 'id'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:44:46.772953Z",
     "start_time": "2021-06-20T18:44:46.750267Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(index=str, columns={'id': 'tweet_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:44:51.158605Z",
     "start_time": "2021-06-20T18:44:51.151146Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['tweet_id','retweet_count','reply_count','like_count','quote_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:44:54.967429Z",
     "start_time": "2021-06-20T18:44:54.957921Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:45:02.288496Z",
     "start_time": "2021-06-20T18:45:02.214970Z"
    }
   },
   "outputs": [],
   "source": [
    "def escapeArray(df, column):\n",
    "    if len(df[column]) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        return df[column]\n",
    "\n",
    "for column in list(df):\n",
    "    for i, j in zip(df[column], range(len(df))):\n",
    "        if isinstance(i, np.ndarray):\n",
    "            df[column][j] = 0\n",
    "            \n",
    "df = df.reset_index(drop=True)\n",
    "df['retweet_count'] = df['retweet_count'].astype(int)\n",
    "df['reply_count'] = df['reply_count'].astype(int)\n",
    "df['like_count'] = df['like_count'].astype(int)\n",
    "df['quote_count'] = df['quote_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:45:10.966777Z",
     "start_time": "2021-06-20T18:45:05.957811Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_sql('meta', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:54:00.783420Z",
     "start_time": "2021-06-20T20:54:00.776978Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def auth():\n",
    "    return os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "\n",
    "def create_url(usernames):\n",
    "    # Specify the usernames that you want to lookup below\n",
    "    # You can enter up to 100 comma-separated values.\n",
    "#     usernames = \"69008563\"\n",
    "    user_fields = \"user.fields=description,created_at,public_metrics,location,name,username,verified\"\n",
    "    # User fields are adjustable, options include:\n",
    "    # created_at, description, entities, id, location, name,\n",
    "    # pinned_tweet_id, profile_image_url, protected,\n",
    "    # public_metrics, url, username, verified, and withheld\n",
    "    url = \"https://api.twitter.com/2/users?ids={}&{}\".format(usernames, user_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def main():\n",
    "    bearer_token = auth()\n",
    "    url = create_url()\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:56:10.807232Z",
     "start_time": "2021-06-20T18:56:10.780276Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406593716555505668</td>\n",
       "      <td>2590166742</td>\n",
       "      <td>2021-06-20T12:44:09.000Z</td>\n",
       "      <td>Currently 24C/75F at Paul Ricard the track sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1406593717113339905</td>\n",
       "      <td>443677496</td>\n",
       "      <td>2021-06-20T12:44:10.000Z</td>\n",
       "      <td>Hab noch keine vollständige Meinung zum neuen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1406593718430453766</td>\n",
       "      <td>41781539</td>\n",
       "      <td>2021-06-20T12:44:10.000Z</td>\n",
       "      <td>LEWIS HAMILTON!!! #FrenchGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1406593732183482377</td>\n",
       "      <td>2273878903</td>\n",
       "      <td>2021-06-20T12:44:13.000Z</td>\n",
       "      <td>Watching my first #F1 I think I’m just going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1406593734444212226</td>\n",
       "      <td>4648175957</td>\n",
       "      <td>2021-06-20T12:44:14.000Z</td>\n",
       "      <td>Hoje de manhã vou revezar entre secar o Hamilt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20455</th>\n",
       "      <td>1406624674038128644</td>\n",
       "      <td>2210684323</td>\n",
       "      <td>2021-06-20T14:47:10.000Z</td>\n",
       "      <td>Get rid of the 'Driver of the Day' radio inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20456</th>\n",
       "      <td>1406624676156252168</td>\n",
       "      <td>707503315</td>\n",
       "      <td>2021-06-20T14:47:11.000Z</td>\n",
       "      <td>#Formula1 • @SChecoPerez logra subirse al podi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20457</th>\n",
       "      <td>1406624679671046147</td>\n",
       "      <td>12846</td>\n",
       "      <td>2021-06-20T14:47:12.000Z</td>\n",
       "      <td>Tremenda carrera la de hoy!!! Esta entretenida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20458</th>\n",
       "      <td>1406624680690081795</td>\n",
       "      <td>2814968690</td>\n",
       "      <td>2021-06-20T14:47:12.000Z</td>\n",
       "      <td>What a race! Amazing drive by Max Verstappen. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>1406624683538141186</td>\n",
       "      <td>57343439</td>\n",
       "      <td>2021-06-20T14:47:13.000Z</td>\n",
       "      <td>Those trophies are absolutely terrible. Imagin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20460 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweet_id   author_id                created_at  \\\n",
       "0      1406593716555505668  2590166742  2021-06-20T12:44:09.000Z   \n",
       "1      1406593717113339905   443677496  2021-06-20T12:44:10.000Z   \n",
       "2      1406593718430453766    41781539  2021-06-20T12:44:10.000Z   \n",
       "3      1406593732183482377  2273878903  2021-06-20T12:44:13.000Z   \n",
       "4      1406593734444212226  4648175957  2021-06-20T12:44:14.000Z   \n",
       "...                    ...         ...                       ...   \n",
       "20455  1406624674038128644  2210684323  2021-06-20T14:47:10.000Z   \n",
       "20456  1406624676156252168   707503315  2021-06-20T14:47:11.000Z   \n",
       "20457  1406624679671046147       12846  2021-06-20T14:47:12.000Z   \n",
       "20458  1406624680690081795  2814968690  2021-06-20T14:47:12.000Z   \n",
       "20459  1406624683538141186    57343439  2021-06-20T14:47:13.000Z   \n",
       "\n",
       "                                                raw_text  \n",
       "0      Currently 24C/75F at Paul Ricard the track sur...  \n",
       "1      Hab noch keine vollständige Meinung zum neuen ...  \n",
       "2                            LEWIS HAMILTON!!! #FrenchGP  \n",
       "3      Watching my first #F1 I think I’m just going t...  \n",
       "4      Hoje de manhã vou revezar entre secar o Hamilt...  \n",
       "...                                                  ...  \n",
       "20455  Get rid of the 'Driver of the Day' radio inter...  \n",
       "20456  #Formula1 • @SChecoPerez logra subirse al podi...  \n",
       "20457  Tremenda carrera la de hoy!!! Esta entretenida...  \n",
       "20458  What a race! Amazing drive by Max Verstappen. ...  \n",
       "20459  Those trophies are absolutely terrible. Imagin...  \n",
       "\n",
       "[20460 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df = data_df.drop_duplicates('author_id', keep='first').reset_index(drop=True)\n",
    "author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T18:57:54.562124Z",
     "start_time": "2021-06-20T18:57:54.303067Z"
    }
   },
   "outputs": [],
   "source": [
    "def auth():\n",
    "    return os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "ids = '1364879051438002176,1350309702'\n",
    "user_fields = \"user.fields=description,created_at,public_metrics,location,name,username,verified\"\n",
    "r = requests.request(\"GET\", 'https://api.twitter.com/2/users/{}?expansions=pinned_tweet_id&{}'.format(ids, user_fields), headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:52:11.311000Z",
     "start_time": "2021-06-20T20:52:10.903103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'created_at': '2021-02-25T10:05:11.000Z', 'location': 'India', 'username': 'Khel17934254', 'public_metrics': {'followers_count': 9, 'following_count': 115, 'tweet_count': 27508, 'listed_count': 0}, 'name': 'Khel ख़बर', 'verified': False, 'description': 'Please follow us on Intagram https://t.co/5twmBGY5dF and Facebook khelkhabr', 'id': '1364879051438002176'}, {'created_at': '2013-04-13T21:55:37.000Z', 'location': 'Stoke Ash, England', 'username': 'SFeatley', 'public_metrics': {'followers_count': 397, 'following_count': 987, 'tweet_count': 2568, 'listed_count': 3}, 'name': 'Steven Featley', 'verified': False, 'description': '6x Liver transplants | Content Creator | Owner of SFeatleyTV CHARITY YouTube Channel  | Arsenal & Hamilton Fan | Volunteer For CLDF  | #StillIRise.', 'id': '1350309702'}]}\n"
     ]
    }
   ],
   "source": [
    "headers = create_headers(bearer_token)\n",
    "ids = 'ids=1364879051438002176,1350309702'\n",
    "r = requests.request(\"GET\", 'https://api.twitter.com/2/users?{}&{}'.format(ids, user_fields), headers=headers)\n",
    "print(json.loads(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:49:07.060329Z",
     "start_time": "2021-06-20T20:49:07.057707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:53:25.443270Z",
     "start_time": "2021-06-20T20:53:25.439977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2590166742,443677496,41781539,2273878903,4648175957,1405862551250903040,3298415044,1228365703486545925,934461876309839872,4607264653,2675145414,1081063545461186560,97050667,1406105241657937923,1298261221980827654,1214918155526651904,406326008,1143541105369202688,28039562,2847430133,1854496014,1367203592,2598689675,1128098521830150144,547957320,70131679,2277937115,1234955542533197825,18016521,24276976,836713582079295488,50785047,3239509871,3290301301,111416958,1110350069675503618,872472139466555393,1234946158264373248,1116995788649971713,1234953194398212099,628786129,1100022872922341377,1300844179661238273,60868886,94438597,19914423,1124585346052890624,9290152,173449565,320266494,163518481,1329169727684554753,65691630,2519242866,48593376,748234411422920705,756868705523564546,282447944,2637582405,472705227,260467752,1122153434881282048,22677822,996145596200255488,74797302,709766541710127104,1057621820,271724821,22879111,210501383,2163291222,1040742121647398914,1320387150228148225,2312058446,1299044123928821760,928496256,168706870,1067503620529119232,823789534542524416,369553879,1213477672644251648,351949476,114249906,43856763,1270078496,816029640775127040,3215935997,557352016,361282556,180758667,841456647914442752,1292278864488480774,2265685644,2463734976,1291493747356827648,994741592,83250663,1384276955244077057,16417285'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T20:57:00.252408Z",
     "start_time": "2021-06-20T20:54:35.259137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "0\n",
      "200\n",
      "1\n",
      "200\n",
      "2\n",
      "200\n",
      "3\n",
      "200\n",
      "4\n",
      "200\n",
      "5\n",
      "200\n",
      "6\n",
      "200\n",
      "7\n",
      "200\n",
      "8\n",
      "200\n",
      "9\n",
      "200\n",
      "10\n",
      "200\n",
      "11\n",
      "200\n",
      "12\n",
      "200\n",
      "13\n",
      "200\n",
      "14\n",
      "200\n",
      "15\n",
      "200\n",
      "16\n",
      "200\n",
      "17\n",
      "200\n",
      "18\n",
      "200\n",
      "19\n",
      "200\n",
      "20\n",
      "200\n",
      "21\n",
      "200\n",
      "22\n",
      "200\n",
      "23\n",
      "200\n",
      "24\n",
      "200\n",
      "25\n",
      "200\n",
      "26\n",
      "200\n",
      "27\n",
      "200\n",
      "28\n",
      "200\n",
      "29\n",
      "200\n",
      "30\n",
      "200\n",
      "31\n",
      "200\n",
      "32\n",
      "200\n",
      "33\n",
      "200\n",
      "34\n",
      "200\n",
      "35\n",
      "200\n",
      "36\n",
      "200\n",
      "37\n",
      "200\n",
      "38\n",
      "200\n",
      "39\n",
      "200\n",
      "40\n",
      "200\n",
      "41\n",
      "200\n",
      "42\n",
      "200\n",
      "43\n",
      "200\n",
      "44\n",
      "200\n",
      "45\n",
      "200\n",
      "46\n",
      "200\n",
      "47\n",
      "200\n",
      "48\n",
      "200\n",
      "49\n",
      "200\n",
      "50\n",
      "200\n",
      "51\n",
      "200\n",
      "52\n",
      "200\n",
      "53\n",
      "200\n",
      "54\n",
      "200\n",
      "55\n",
      "200\n",
      "56\n",
      "200\n",
      "57\n",
      "200\n",
      "58\n",
      "200\n",
      "59\n",
      "200\n",
      "60\n",
      "200\n",
      "61\n",
      "200\n",
      "62\n",
      "200\n",
      "63\n",
      "200\n",
      "64\n",
      "200\n",
      "65\n",
      "200\n",
      "66\n",
      "200\n",
      "67\n",
      "200\n",
      "68\n",
      "200\n",
      "69\n",
      "200\n",
      "70\n",
      "200\n",
      "71\n",
      "200\n",
      "72\n",
      "200\n",
      "73\n",
      "200\n",
      "74\n",
      "200\n",
      "75\n",
      "200\n",
      "76\n",
      "200\n",
      "77\n",
      "200\n",
      "78\n",
      "200\n",
      "79\n",
      "200\n",
      "80\n",
      "200\n",
      "81\n",
      "200\n",
      "82\n",
      "200\n",
      "83\n",
      "200\n",
      "84\n",
      "200\n",
      "85\n",
      "200\n",
      "86\n",
      "200\n",
      "87\n",
      "200\n",
      "88\n",
      "200\n",
      "89\n",
      "200\n",
      "90\n",
      "200\n",
      "91\n",
      "200\n",
      "92\n",
      "200\n",
      "93\n",
      "200\n",
      "94\n",
      "200\n",
      "95\n",
      "200\n",
      "96\n",
      "200\n",
      "97\n",
      "200\n",
      "98\n",
      "200\n",
      "99\n",
      "200\n",
      "100\n",
      "200\n",
      "101\n",
      "200\n",
      "102\n",
      "200\n",
      "103\n",
      "200\n",
      "104\n",
      "200\n",
      "105\n",
      "200\n",
      "106\n",
      "200\n",
      "107\n",
      "200\n",
      "108\n",
      "200\n",
      "109\n",
      "200\n",
      "110\n",
      "200\n",
      "111\n",
      "200\n",
      "112\n",
      "200\n",
      "113\n",
      "200\n",
      "114\n",
      "200\n",
      "115\n",
      "200\n",
      "116\n",
      "200\n",
      "117\n",
      "200\n",
      "118\n",
      "200\n",
      "119\n",
      "200\n",
      "120\n",
      "200\n",
      "121\n",
      "200\n",
      "122\n",
      "200\n",
      "123\n",
      "200\n",
      "124\n",
      "200\n",
      "125\n",
      "200\n",
      "126\n",
      "200\n",
      "127\n",
      "200\n",
      "128\n",
      "200\n",
      "129\n",
      "200\n",
      "130\n",
      "200\n",
      "131\n",
      "200\n",
      "132\n",
      "200\n",
      "133\n",
      "200\n",
      "134\n",
      "200\n",
      "135\n",
      "200\n",
      "136\n",
      "200\n",
      "137\n",
      "200\n",
      "138\n",
      "200\n",
      "139\n",
      "200\n",
      "140\n",
      "200\n",
      "141\n",
      "200\n",
      "142\n",
      "200\n",
      "143\n",
      "200\n",
      "144\n",
      "200\n",
      "145\n",
      "200\n",
      "146\n",
      "200\n",
      "147\n",
      "200\n",
      "148\n",
      "200\n",
      "149\n",
      "200\n",
      "150\n",
      "200\n",
      "151\n",
      "200\n",
      "152\n",
      "200\n",
      "153\n",
      "200\n",
      "154\n",
      "200\n",
      "155\n",
      "200\n",
      "156\n",
      "200\n",
      "157\n",
      "200\n",
      "158\n",
      "200\n",
      "159\n",
      "200\n",
      "160\n",
      "200\n",
      "161\n",
      "200\n",
      "162\n",
      "200\n",
      "163\n",
      "200\n",
      "164\n",
      "200\n",
      "165\n",
      "200\n",
      "166\n",
      "200\n",
      "167\n",
      "200\n",
      "168\n",
      "200\n",
      "169\n",
      "200\n",
      "170\n",
      "200\n",
      "171\n",
      "200\n",
      "172\n",
      "200\n",
      "173\n",
      "200\n",
      "174\n",
      "200\n",
      "175\n",
      "200\n",
      "176\n",
      "200\n",
      "177\n",
      "200\n",
      "178\n",
      "200\n",
      "179\n",
      "200\n",
      "180\n",
      "200\n",
      "181\n",
      "200\n",
      "182\n",
      "200\n",
      "183\n",
      "200\n",
      "184\n",
      "200\n",
      "185\n",
      "200\n",
      "186\n",
      "200\n",
      "187\n",
      "200\n",
      "188\n",
      "200\n",
      "189\n",
      "200\n",
      "190\n",
      "200\n",
      "191\n",
      "200\n",
      "192\n",
      "200\n",
      "193\n",
      "200\n",
      "194\n",
      "200\n",
      "195\n",
      "200\n",
      "196\n",
      "200\n",
      "197\n",
      "200\n",
      "198\n",
      "200\n",
      "199\n",
      "200\n",
      "200\n",
      "200\n",
      "201\n",
      "200\n",
      "202\n",
      "200\n",
      "203\n",
      "200\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batches = math.ceil(len(author_df)/batch_size)\n",
    "for batch in range(batches):   \n",
    "    try:\n",
    "        ids = str(list(author_df['author_id'][batch*batch_size:batch*batch_size+batch_size-1]))\\\n",
    "            .replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\")\n",
    "        bearer_token = auth()\n",
    "        url = create_url(ids)\n",
    "        headers = create_headers(bearer_token)\n",
    "        json_response = connect_to_endpoint(url, headers)\n",
    "        col.insert_many(json_response['data'])\n",
    "        print(batch)\n",
    "    except Exception:\n",
    "        print(batch)\n",
    "#     print(batch*batch_size, batch*batch_size+batch_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:46.436093Z",
     "start_time": "2021-06-20T21:08:46.245092Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(col.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:46.589265Z",
     "start_time": "2021-06-20T21:08:46.581534Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[1074:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:47.856219Z",
     "start_time": "2021-06-20T21:08:47.853028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'followers_count': 842,\n",
       " 'following_count': 512,\n",
       " 'tweet_count': 100986,\n",
       " 'listed_count': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['public_metrics'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:50.411720Z",
     "start_time": "2021-06-20T21:08:48.327405Z"
    }
   },
   "outputs": [],
   "source": [
    "df['followers_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'followers_count'), 1)\n",
    "df['following_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'following_count'), 1)\n",
    "df['tweet_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'tweet_count'), 1)\n",
    "df['listed_count'] = df.apply(lambda df: parse_json(df, 'public_metrics', 'listed_count'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:50.646957Z",
     "start_time": "2021-06-20T21:08:50.413469Z"
    }
   },
   "outputs": [],
   "source": [
    "df['name'] = df.apply(lambda df: getRawText(df, 'name'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:50.679335Z",
     "start_time": "2021-06-20T21:08:50.649681Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(index=str, columns={'id': 'author_id'})\n",
    "df = df[[\n",
    "    'author_id', 'description', 'verified', 'username', 'created_at', 'name',\n",
    "    'location', 'followers_count', 'following_count','tweet_count', 'listed_count'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:08:55.553420Z",
     "start_time": "2021-06-20T21:08:52.357570Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres@localhost:5432/frenchgp')\n",
    "df.to_sql('author', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-20T21:07:17.276343Z",
     "start_time": "2021-06-20T21:07:17.211367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withheld {'country_codes': ['RU']} 7\n",
      "withheld {'country_codes': ['RU']} 7\n"
     ]
    }
   ],
   "source": [
    "for i, idx in zip(list(df), range(len(df))):\n",
    "    for j in df[i]:\n",
    "        if isinstance(j, dict):\n",
    "            print(i, j, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
